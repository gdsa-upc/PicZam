{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amb la present notebook, mostrarem les evolucions del projecte duts a terme per a la sessió 4.\n",
    "\n",
    " En aquesta, treballarem els següents blocs : \n",
    "\n",
    "    1. Build Database. Utilitzem la funció build_database, que genera un fitxen .txt, que contindrà una llista\n",
    "    amb les ID de les imatges que tenim a la nostra base de dades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_database(params):\n",
    "\n",
    "    # List images\n",
    "\n",
    "    image_names = os.listdir(os.path.join(params['root'],\n",
    "\n",
    "                             params['database'],params['split'],'images'))\n",
    "\n",
    "    # File to be saved\n",
    "\n",
    "    file = open(os.path.join(params['root'],params['root_save'],\n",
    "\n",
    "                             params['image_lists'],\n",
    "\n",
    "                             params['split'] + '.txt'),'w'\n",
    "\n",
    "\n",
    "    # Save image list to disk\n",
    "\n",
    "    for imname in image_names:\n",
    "\n",
    "        file.write(imname + \"\\n\")\n",
    "\n",
    "    file.close()\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    params = get_params()\n",
    "\n",
    "    for split in ['train','val','test']:\n",
    "\n",
    "        params['split'] = split\n",
    "\n",
    "        build_database(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Feature Extraction. \n",
    "\n",
    "En aquest bloc es crida les funcions get_params y get_feaetures. Amb la primera, definim tots els paràmetres que s'utilitzaran en les funcions següents, per tal de reduïr la redundancia del codi i millorar-ne la seva lectura. També definirem la ruta al projecte (path) que apunta a la carpeta on tenim la base de dades i els scripts. \n",
    "\n",
    "En el cas de la funció get_features, llegeix el nom de les imatges de la llista, inizialitza el detector de punts clau i n'extreu les característiques en vectors, i crea un diccionari on es guarden els descriptors per a cada imatge. Per tant, creem un descriptor per a cada imatge de la carpeta d'entrenament i de validació mitjançant la tècnica d'agregació Bag of Words que consisteix en entrenar un llibre de codis (codebook) de paraules visuals i construïnt un descriptor d'imatges, codificant el nombre de vegades que apareix cada paraula del codebook en la imatge. \n",
    "\n",
    "Per tal de construir el codebook, nomès utilitzarem les imatges d'entrenament, de les quals obtindrem els seus descriptors i els emmagatzemarem  en un vector tipus numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.get_features as GF# Make sure that we are using training images only !\n",
    "params['split'] = 'train'\n",
    "\n",
    "t = time.time()\n",
    "X, pca, scaler = GF.stack_features(params)\n",
    "\n",
    "print \"Done. Time elapsed:\", time.time() - t\n",
    "print np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable X, conté ara el vector descrit, i les variables pca i scaler contenen les transformacions que s'han aplicat a X, com la reducció de la mida de les imatges per tal de reduir el temps d'execució de l'escript.\n",
    "\n",
    "Tot seguit, procedirem a entrenar el nostre codebook. Utilitzarem MiniBatchkMeans, que permet processar més descriptors en un menor temps que el Kmeans, ja que en cada iteració no utilitza tot el pool de mostres, sino una submostra de tamany fix. Cal dir però, que perdem perdem qualitat de clúster.\n",
    "\n",
    "Acontinuació,  construim els vectors Bag of Words per a cada imatge d'entrenament i validació i creem el diccionari que relaciona cada imarge am el seu vector de descriptors BoW. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-91f5361789b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mGF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Done. Time elapsed for training set:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Switch to validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "GF.get_features(params)\n",
    "\n",
    "print \"Done. Time elapsed for training set:\", time.time() - t\n",
    "# Switch to validation set\n",
    "params['split'] = 'val'\n",
    "\n",
    "t = time.time()\n",
    "# Run again\n",
    "GF.get_features(params)\n",
    "\n",
    "print \"Done. Time elapsed for validation set:\", time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
